{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfhdE_eFl3NT"
      },
      "source": [
        "# 実験 II 演習\n",
        "言語処理 100 本ノックの「第 2 章: UNIX コマンド」で UNIX コマンドのうち\n",
        "言語処理と関連の強いコマンドに慣れる．  \n",
        "またそれらのコマンドでできることを Python で記述することで\n",
        "言語処理の基本的な前処理に習熟する．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GJBLqIvjlP-"
      },
      "source": [
        "# 第2章: UNIXコマンド\n",
        "[popular-names.txt](https://nlp100.github.io/data/popular-names.txt) は，アメリカで生まれた赤ちゃんの「名前」「性別」「人数」「年」をタブ区切り形式で格納したファイルである．以下の処理を行うプログラムを作成し，[popular-names.txt](https://nlp100.github.io/data/popular-names.txt) を入力ファイルとして実行せよ．さらに，同様の処理をUNIXコマンドでも実行し，プログラムの実行結果を確認せよ．\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4kCrBSMk4gr"
      },
      "source": [
        "# 10. 行数のカウント\n",
        "行数をカウントせよ．確認にはwcコマンドを用いよ．\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6W5fvR3LlX-c",
        "outputId": "c275dbb2-ac69-4f63-b83c-0e7e853109f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2780\n"
          ]
        }
      ],
      "source": [
        "import urllib.request\n",
        "count=0\n",
        "f= urllib.request.urlopen('https://nlp100.github.io/data/popular-names.txt')\n",
        "for line in f:\n",
        "  count+=1\n",
        "print(count)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-u1k1Ro4k83b"
      },
      "source": [
        "# 11. タブをスペースに置換\n",
        "タブ1文字につきスペース1文字に置換せよ．確認にはsedコマンド，trコマンド，もしくはexpandコマンドを用いよ．\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSecLSMQlYdf",
        "outputId": "e62ae0f0-9a4a-4a48-bfa2-783197fdadc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mary F 7065 1880\n",
            "Anna F 2604 1880\n",
            "Emma F 2003 1880\n",
            "Elizabeth F 1939 1880\n",
            "Minnie F 1746 1880\n",
            "Margaret F 1578 1880\n",
            "Ida F 1472 1880\n",
            "Alice F 1414 1880\n",
            "Bertha F 1320 1880\n",
            "Sarah F 1288 1880\n",
            "John M 9655 1880\n",
            "William M 9532 1880\n",
            "James M 5927 1880\n",
            "Charles M 5348 1880\n",
            "George M 5126 1880\n",
            "Frank M 3242 1880\n",
            "Joseph M 2632 1880\n",
            "Thomas M 2534 1880\n",
            "Henry M 2444 1880\n",
            "Robert M 2415 1880\n",
            "Mary F 6919 1881\n",
            "Anna F 2698 1881\n",
            "Emma F 2034 1881\n",
            "Elizabeth F 1852 1881\n",
            "Margaret F 1658 1881\n",
            "Minnie F 1653 1881\n",
            "Ida F 1439 1881\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import urllib.request\n",
        "\n",
        "f= urllib.request.urlopen('https://nlp100.github.io/data/popular-names.txt')\n",
        "\n",
        "f_popular=open(\"popular-names.txt\",mode=\"w\")\n",
        "lines=f.read().decode()\n",
        "\n",
        "f_popular.write(lines)\n",
        "lines_tab_to_space=lines.replace(\"\\t\",\" \")\n",
        "\n",
        "print(lines_tab_to_space[0:500])\n",
        "\n",
        "with open(\"popular-names_tab_to_space.txt\",mode=\"w\") as f_re:\n",
        "  f_re.write(lines_tab_to_space)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQpzd1Gjk_Vr"
      },
      "source": [
        "# 12. 1列目をcol1.txtに，2列目をcol2.txtに保存\n",
        "各行の1列目だけを抜き出したものをcol1.txtに，2列目だけを抜き出したものをcol2.txtとしてファイルに保存せよ．確認にはcutコマンドを用いよ．\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WJKr-fY6lZFI"
      },
      "outputs": [],
      "source": [
        "with open(\"popular-names_tab_to_space.txt\",mode=\"r\") as f_tab_to_space:\n",
        "  with open(\"col1.txt\",mode=\"w\") as f1:\n",
        "    for data in f_tab_to_space:\n",
        "      f1.write(data.split(\" \")[0])\n",
        "      f1.write(\"\\n\")\n",
        "\n",
        "with open(\"popular-names_tab_to_space.txt\",mode=\"r\") as f_tab_to_space:\n",
        "  with open(\"col2.txt\",mode=\"w\") as f2:\n",
        "    for data in f_tab_to_space:\n",
        "      f2.write(data.split(\" \")[1])\n",
        "      f2.write(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJimg2cZlCcC"
      },
      "source": [
        "# 13. col1.txtとcol2.txtをマージ\n",
        "12で作ったcol1.txtとcol2.txtを結合し，元のファイルの1列目と2列目をタブ区切りで並べたテキストファイルを作成せよ．確認にはpasteコマンドを用いよ．\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EM8HA52LlZyS"
      },
      "outputs": [],
      "source": [
        "f1=open(\"col1.txt\",mode=\"r\")\n",
        "f2=open(\"col2.txt\",mode=\"r\")\n",
        "\n",
        "f3=open(\"marge_col1_col2.txt\",mode=\"w\")\n",
        "for data1,data2 in zip(f1,f2):\n",
        "  f3.write(data1[:-1]+'\\t'+data2)\n",
        "\n",
        "#f3=open(\"marge_col1_col2.txt\",mode=\"r\")\n",
        "#print(f3.read()[0:30])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "984OfysAlEml"
      },
      "source": [
        "#14. 先頭からN行を出力\n",
        "自然数Nをコマンドライン引数などの手段で受け取り，入力のうち先頭のN行だけを表示せよ．確認にはheadコマンドを用いよ．\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tgl4XfD4laUf",
        "outputId": "015ac387-e527-490e-ff1d-f5df97c5c707"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mary\tF\n",
            "Anna\tF\n",
            "Emma\tF\n"
          ]
        }
      ],
      "source": [
        "N=int(input())\n",
        "count=0\n",
        "f3=open(\"marge_col1_col2.txt\",mode=\"r\")\n",
        "for data in f3:\n",
        "  print(data[:-1])\n",
        "  count+=1\n",
        "  if count==N:\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pah1LCoKlGl0"
      },
      "source": [
        "#15. 末尾のN行を出力\n",
        "自然数Nをコマンドライン引数などの手段で受け取り，入力のうち末尾のN行だけを表示せよ．確認にはtailコマンドを用いよ．\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y26tRApUla3H",
        "outputId": "e7852c51-b5e5-4375-b7de-aacc697e0af7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lucas\tM\t12585\t2018\n",
            "Mason\tM\t12435\t2018\n",
            "Logan\tM\t12352\t2018\n"
          ]
        }
      ],
      "source": [
        "N=int(input())\n",
        "\n",
        "count=0\n",
        "f3=open(\"popular-names.txt\",mode=\"r\")\n",
        "\n",
        "list=[]\n",
        "\n",
        "for data in f3:\n",
        "  list.append(data)\n",
        "#print(list)\n",
        "\n",
        "for data in list[len(list)-N:]:\n",
        "  print(data[:-1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnDWeXr0lIDT"
      },
      "source": [
        "#16. ファイルをN分割する\n",
        "自然数Nをコマンドライン引数などの手段で受け取り，入力のファイルを行単位でN分割せよ．同様の処理をsplitコマンドで実現せよ．\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiD7Wc3JlbV2",
        "outputId": "3c94f789-4701-4110-884e-045959678e1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "元データの行数＝ 2780\n",
            "分割ファイル１つあたりの行数＝ 926\n"
          ]
        }
      ],
      "source": [
        "N=int(input())\n",
        "f=open(\"popular-names.txt\",mode=\"r\")\n",
        "\n",
        "count=0\n",
        "for i in f:\n",
        "  count+=1\n",
        "\n",
        "print(\"元データの行数＝\",count)\n",
        "\n",
        "part_lines=int(count/N)\n",
        "print(\"分割ファイル１つあたりの行数＝\",part_lines)\n",
        "\n",
        "f=open(\"popular-names.txt\",mode=\"r\")\n",
        "\n",
        "part=1\n",
        "f_part= open(\"popular-names_{0}.txt\".format(part),mode=\"w\")\n",
        "\n",
        "j=0\n",
        "for i in f:\n",
        "    #ファイルへ書き込み \n",
        "  f_part.write(i[:-1])\n",
        "    #一行書きこむごとにjを１増やす\n",
        "  j+=1\n",
        "    #jが１ファイル分になったらok\n",
        "  if j==part_lines:\n",
        "    #jを初期化\n",
        "    j=0\n",
        "    part+=1\n",
        "    f_part.close()\n",
        "    if part>N:\n",
        "      break\n",
        "    f_part= open(\"popular-names_{0}.txt\".format(part),mode=\"w\") \n",
        "  else:\n",
        "    f_part.write(\"\\n\")\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAMhXhqglNAb"
      },
      "source": [
        "# 17. １列目の文字列の異なり\n",
        "1列目の文字列の種類（異なる文字列の集合）を求めよ．確認にはcut, sort, uniqコマンドを用いよ．\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrsfaSnTlb59",
        "outputId": "d6a1f7b6-626f-4073-8ec3-090b3a2bf72f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Oliver', 'Hannah', 'Chloe', 'Larry', 'Annie', 'Minnie', 'Linda', 'Nicole', 'Austin', 'Ida', 'Doris', 'Ethel', 'Olivia', 'Ashley', 'Amanda', 'Helen', 'Alexis', 'Cynthia', 'Lisa', 'Bertha', 'Edward', 'Jacob', 'Lauren', 'Henry', 'Rebecca', 'Pamela', 'Mary', 'Mildred', 'Steven', 'Gary', 'Rachel', 'George', 'Lori', 'Florence', 'Jayden', 'Joan', 'Heather', 'Deborah', 'Michael', 'Joshua', 'Brandon', 'Sophia', 'Donald', 'Bessie', 'Mason', 'Liam', 'Scott', 'Jeffrey', 'Frances', 'Evelyn', 'Sarah', 'Elijah', 'Mia', 'Abigail', 'Matthew', 'Kelly', 'Ronald', 'Stephanie', 'Anna', 'Emma', 'Thomas', 'Harry', 'Barbara', 'Elizabeth', 'Amy', 'Julie', 'Noah', 'Richard', 'Walter', 'Charlotte', 'Margaret', 'Brittany', 'Sharon', 'Justin', 'Clara', 'Ruth', 'Carol', 'Taylor', 'Jason', 'Isabella', 'Aiden', 'Kimberly', 'Susan', 'Logan', 'Patricia', 'Marie', 'Madison', 'Daniel', 'Betty', 'Emily', 'Ava', 'Nancy', 'Brian', 'Lucas', 'Karen', 'Tammy', 'Andrew', 'Benjamin', 'Megan', 'Charles', 'Donna', 'Alice', 'Michelle', 'Jennifer', 'Samantha', 'Amelia', 'John', 'James', 'Sandra', 'Kathleen', 'Debra', 'Anthony', 'Harper', 'David', 'Shirley', 'Dorothy', 'Angela', 'Virginia', 'William', 'Lillian', 'Ethan', 'Tyler', 'Laura', 'Christopher', 'Joseph', 'Mark', 'Judith', 'Melissa', 'Jessica', 'Robert', 'Alexander', 'Tracy', 'Frank', 'Carolyn', 'Nicholas', 'Crystal'}\n",
            "136\n"
          ]
        }
      ],
      "source": [
        "#上の分割課題でファイルを分割しすぎてしまった場合に使用\n",
        "\"\"\"import os\n",
        "for i in range(1,1392):\n",
        "  os.remove(\"/content/popular-names_{0}.txt\".format(i))\n",
        "\"\"\"\n",
        "s=set()\n",
        "f=open(\"popular-names.txt\",mode=\"r\")\n",
        "\n",
        "for lines in f:\n",
        "  \n",
        "  s.add(lines.split(\"\\t\")[0])\n",
        "print(s)\n",
        "print(len(s))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-N82SEnOlP-E"
      },
      "source": [
        "# 18. 各行を3コラム目の数値の降順にソート\n",
        "各行を3コラム目の数値の逆順で整列せよ（注意: 各行の内容は変更せずに並び替えよ）．確認にはsortコマンドを用いよ（この問題はコマンドで実行した時の結果と合わなくてもよい）．\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-iJcBpGjlcl7"
      },
      "outputs": [],
      "source": [
        "f=open(\"popular-names.txt\",mode=\"r\")\n",
        "\n",
        "l=[]\n",
        "for data in f:\n",
        "  list=data.split(\"\\t\")\n",
        "  list[2]=int(list[2])\n",
        "  l.append(list)\n",
        "#print(l)\n",
        "\n",
        "from operator import itemgetter\n",
        "\n",
        "l_sorted = sorted(l, key=itemgetter(2),reverse=True)\n",
        "\n",
        "#print(l_sorted)\n",
        "\n",
        "#write in file\n",
        "\n",
        "f_sorted=open(\"sorted_popular-names.txt\",mode=\"w\")\n",
        "for data1 in l_sorted:\n",
        "  for data2 in data1:\n",
        "\n",
        "    f_sorted.write(str(data2))\n",
        "\n",
        "    if str(data2)[-1]!=\"\\n\":\n",
        "      #出力にソート結果は出さずfileに書きこんだ\n",
        "      f_sorted.write(\"\\t\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7VDHgMmlSNN"
      },
      "source": [
        "# 19. 各行の1コラム目の文字列の出現頻度を求め，出現頻度の高い順に並べる\n",
        "各行の1列目の文字列の出現頻度を求め，その高い順に並べて表示せよ．確認にはcut, uniq, sortコマンドを用いよ．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvgahCgejkiS",
        "outputId": "4df770e5-fa99-4792-c693-260816f76dc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Mary': 92, 'Anna': 41, 'Emma': 35, 'Elizabeth': 73, 'Minnie': 12, 'Margaret': 60, 'Ida': 8, 'Alice': 10, 'Bertha': 12, 'Sarah': 26, 'John': 108, 'William': 111, 'James': 118, 'Charles': 75, 'George': 58, 'Frank': 43, 'Joseph': 70, 'Thomas': 58, 'Henry': 23, 'Robert': 108, 'Annie': 5, 'Edward': 40, 'Clara': 8, 'Florence': 20, 'Ethel': 16, 'Bessie': 2, 'Harry': 7, 'Helen': 45, 'Ruth': 39, 'Marie': 20, 'Lillian': 4, 'Mildred': 24, 'Dorothy': 36, 'Frances': 15, 'Walter': 1, 'Evelyn': 3, 'Virginia': 13, 'Richard': 51, 'Betty': 24, 'Donald': 20, 'Doris': 10, 'Shirley': 14, 'Barbara': 32, 'Patricia': 38, 'Joan': 9, 'Nancy': 22, 'Carol': 15, 'David': 57, 'Ronald': 10, 'Judith': 8, 'Linda': 26, 'Sandra': 16, 'Carolyn': 1, 'Sharon': 7, 'Michael': 74, 'Susan': 24, 'Donna': 12, 'Larry': 2, 'Kathleen': 4, 'Deborah': 13, 'Gary': 5, 'Karen': 18, 'Debra': 9, 'Pamela': 1, 'Cynthia': 11, 'Mark': 16, 'Steven': 7, 'Lisa': 18, 'Jeffrey': 5, 'Lori': 1, 'Kimberly': 14, 'Tammy': 7, 'Angela': 15, 'Michelle': 15, 'Jennifer': 26, 'Melissa': 18, 'Christopher': 43, 'Brian': 13, 'Amy': 14, 'Laura': 1, 'Tracy': 1, 'Julie': 1, 'Jason': 13, 'Scott': 1, 'Stephanie': 17, 'Heather': 15, 'Nicole': 13, 'Matthew': 37, 'Rebecca': 2, 'Jessica': 25, 'Amanda': 20, 'Daniel': 31, 'Kelly': 1, 'Joshua': 31, 'Crystal': 1, 'Ashley': 23, 'Megan': 3, 'Brittany': 10, 'Andrew': 21, 'Justin': 4, 'Samantha': 19, 'Lauren': 2, 'Emily': 26, 'Brandon': 7, 'Tyler': 9, 'Taylor': 8, 'Nicholas': 10, 'Jacob': 25, 'Hannah': 13, 'Austin': 4, 'Alexis': 8, 'Rachel': 1, 'Madison': 18, 'Abigail': 17, 'Olivia': 18, 'Ethan': 15, 'Anthony': 6, 'Isabella': 15, 'Ava': 14, 'Sophia': 13, 'Chloe': 4, 'Alexander': 8, 'Mia': 10, 'Jayden': 5, 'Noah': 10, 'Aiden': 3, 'Mason': 8, 'Liam': 7, 'Charlotte': 5, 'Harper': 3, 'Benjamin': 4, 'Elijah': 3, 'Amelia': 2, 'Logan': 2, 'Oliver': 2, 'Lucas': 1}\n",
            "[('James', 118), ('William', 111), ('John', 108), ('Robert', 108), ('Mary', 92), ('Charles', 75), ('Michael', 74), ('Elizabeth', 73), ('Joseph', 70), ('Margaret', 60), ('George', 58), ('Thomas', 58), ('David', 57), ('Richard', 51), ('Helen', 45), ('Frank', 43), ('Christopher', 43), ('Anna', 41), ('Edward', 40), ('Ruth', 39), ('Patricia', 38), ('Matthew', 37), ('Dorothy', 36), ('Emma', 35), ('Barbara', 32), ('Daniel', 31), ('Joshua', 31), ('Sarah', 26), ('Linda', 26), ('Jennifer', 26), ('Emily', 26), ('Jessica', 25), ('Jacob', 25), ('Mildred', 24), ('Betty', 24), ('Susan', 24), ('Henry', 23), ('Ashley', 23), ('Nancy', 22), ('Andrew', 21), ('Florence', 20), ('Marie', 20), ('Donald', 20), ('Amanda', 20), ('Samantha', 19), ('Karen', 18), ('Lisa', 18), ('Melissa', 18), ('Madison', 18), ('Olivia', 18), ('Stephanie', 17), ('Abigail', 17), ('Ethel', 16), ('Sandra', 16), ('Mark', 16), ('Frances', 15), ('Carol', 15), ('Angela', 15), ('Michelle', 15), ('Heather', 15), ('Ethan', 15), ('Isabella', 15), ('Shirley', 14), ('Kimberly', 14), ('Amy', 14), ('Ava', 14), ('Virginia', 13), ('Deborah', 13), ('Brian', 13), ('Jason', 13), ('Nicole', 13), ('Hannah', 13), ('Sophia', 13), ('Minnie', 12), ('Bertha', 12), ('Donna', 12), ('Cynthia', 11), ('Alice', 10), ('Doris', 10), ('Ronald', 10), ('Brittany', 10), ('Nicholas', 10), ('Mia', 10), ('Noah', 10), ('Joan', 9), ('Debra', 9), ('Tyler', 9), ('Ida', 8), ('Clara', 8), ('Judith', 8), ('Taylor', 8), ('Alexis', 8), ('Alexander', 8), ('Mason', 8), ('Harry', 7), ('Sharon', 7), ('Steven', 7), ('Tammy', 7), ('Brandon', 7), ('Liam', 7), ('Anthony', 6), ('Annie', 5), ('Gary', 5), ('Jeffrey', 5), ('Jayden', 5), ('Charlotte', 5), ('Lillian', 4), ('Kathleen', 4), ('Justin', 4), ('Austin', 4), ('Chloe', 4), ('Benjamin', 4), ('Evelyn', 3), ('Megan', 3), ('Aiden', 3), ('Harper', 3), ('Elijah', 3), ('Bessie', 2), ('Larry', 2), ('Rebecca', 2), ('Lauren', 2), ('Amelia', 2), ('Logan', 2), ('Oliver', 2), ('Walter', 1), ('Carolyn', 1), ('Pamela', 1), ('Lori', 1), ('Laura', 1), ('Tracy', 1), ('Julie', 1), ('Scott', 1), ('Kelly', 1), ('Crystal', 1), ('Rachel', 1), ('Lucas', 1)]\n",
            "James\n",
            "William\n",
            "John\n",
            "Robert\n",
            "Mary\n",
            "Charles\n",
            "Michael\n",
            "Elizabeth\n",
            "Joseph\n",
            "Margaret\n",
            "George\n",
            "Thomas\n",
            "David\n",
            "Richard\n",
            "Helen\n",
            "Frank\n",
            "Christopher\n",
            "Anna\n",
            "Edward\n",
            "Ruth\n",
            "Patricia\n",
            "Matthew\n",
            "Dorothy\n",
            "Emma\n",
            "Barbara\n",
            "Daniel\n",
            "Joshua\n",
            "Sarah\n",
            "Linda\n",
            "Jennifer\n",
            "Emily\n",
            "Jessica\n",
            "Jacob\n",
            "Mildred\n",
            "Betty\n",
            "Susan\n",
            "Henry\n",
            "Ashley\n",
            "Nancy\n",
            "Andrew\n",
            "Florence\n",
            "Marie\n",
            "Donald\n",
            "Amanda\n",
            "Samantha\n",
            "Karen\n",
            "Lisa\n",
            "Melissa\n",
            "Madison\n",
            "Olivia\n",
            "Stephanie\n",
            "Abigail\n",
            "Ethel\n",
            "Sandra\n",
            "Mark\n",
            "Frances\n",
            "Carol\n",
            "Angela\n",
            "Michelle\n",
            "Heather\n",
            "Ethan\n",
            "Isabella\n",
            "Shirley\n",
            "Kimberly\n",
            "Amy\n",
            "Ava\n",
            "Virginia\n",
            "Deborah\n",
            "Brian\n",
            "Jason\n",
            "Nicole\n",
            "Hannah\n",
            "Sophia\n",
            "Minnie\n",
            "Bertha\n",
            "Donna\n",
            "Cynthia\n",
            "Alice\n",
            "Doris\n",
            "Ronald\n",
            "Brittany\n",
            "Nicholas\n",
            "Mia\n",
            "Noah\n",
            "Joan\n",
            "Debra\n",
            "Tyler\n",
            "Ida\n",
            "Clara\n",
            "Judith\n",
            "Taylor\n",
            "Alexis\n",
            "Alexander\n",
            "Mason\n",
            "Harry\n",
            "Sharon\n",
            "Steven\n",
            "Tammy\n",
            "Brandon\n",
            "Liam\n",
            "Anthony\n",
            "Annie\n",
            "Gary\n",
            "Jeffrey\n",
            "Jayden\n",
            "Charlotte\n",
            "Lillian\n",
            "Kathleen\n",
            "Justin\n",
            "Austin\n",
            "Chloe\n",
            "Benjamin\n",
            "Evelyn\n",
            "Megan\n",
            "Aiden\n",
            "Harper\n",
            "Elijah\n",
            "Bessie\n",
            "Larry\n",
            "Rebecca\n",
            "Lauren\n",
            "Amelia\n",
            "Logan\n",
            "Oliver\n",
            "Walter\n",
            "Carolyn\n",
            "Pamela\n",
            "Lori\n",
            "Laura\n",
            "Tracy\n",
            "Julie\n",
            "Scott\n",
            "Kelly\n",
            "Crystal\n",
            "Rachel\n",
            "Lucas\n"
          ]
        }
      ],
      "source": [
        "dict={}\n",
        "i=0\n",
        "\n",
        "with open(\"popular-names.txt\",mode=\"r\") as f:\n",
        "  for data in f:\n",
        "    dict.setdefault(data.split(\"\\t\")[0], 0)\n",
        "    dict[data.split(\"\\t\")[0]]+=1\n",
        "\n",
        "  \n",
        "print(dict)\n",
        "print(sorted(dict.items(),key=lambda x:x[1],reverse=True))\n",
        "\n",
        "for name in sorted(dict.items(),key=lambda x:x[1],reverse=True):\n",
        "  print(name[0])\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOKj4ZV1Cj7n"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "1019_1191201152_100Knock2.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "58970072a12a1ea20f1f2868bede9727da334bde1ed56f5c31915c5ac8da21f0"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
